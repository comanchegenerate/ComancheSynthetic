{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3qi1av3XepVdNBig74ujT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comanchegenerate/ComancheSynthetic/blob/main/Comanche_Lang_ID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Original Zero Shot Tests"
      ],
      "metadata": {
        "id": "UsGP8GdOzVmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "7LZHcNj45YF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"dataset\") # Replace with actualt dataset name\n",
        "\n",
        "\n",
        "# Group sentences by language\n",
        "language_data = defaultdict(list)\n",
        "language_data[\"Comanche\"] = df[\"Comanche\"].dropna().tolist()\n",
        "\n",
        "print(language_data)"
      ],
      "metadata": {
        "id": "4CRpyXzK5apR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "zero_shot_samples = {lang: sentences[:len(language_data)] for lang, sentences in language_data.items()}\n",
        "\n",
        "print(zero_shot_samples)"
      ],
      "metadata": {
        "id": "pE5NCZ-j5f3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=\"***********\")  # Replace with your actual API key"
      ],
      "metadata": {
        "id": "IVT6Tfy75iP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # Use GPT-4o or your preferred model\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "tyskHE_85nGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-Shot Evaluation\n",
        "zero_shot_results = []\n",
        "for lang, test_sentences in zero_shot_samples.items():\n",
        "    for sentence in test_sentences:\n",
        "        prompt = f\"You are a linguistics expert who knows every single language that exists in this world. What language is this sentence in?\\n\\nSentence: {sentence}. Reply with only the language itself and nothing else.\"\n",
        "        predicted_lang = query_gpt(prompt)\n",
        "        zero_shot_results.append([lang, sentence, predicted_lang])"
      ],
      "metadata": {
        "id": "KpzVchnL5oK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and save\n",
        "zero_shot_df = pd.DataFrame(zero_shot_results, columns=[\"True Language\", \"Sentence\", \"Predicted Language\"])\n",
        "\n",
        "# Save outputs\n",
        "zero_shot_df.to_csv(\"comanche_id_zero_shot.csv\", index=False)\n",
        "\n",
        "print(\"Experiment complete! Results saved.\")"
      ],
      "metadata": {
        "id": "AasiLEE35vID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterate over an increasing number of few-shot prompts, chart the resulting success rates, and compare the performance of 4o versus 4o-mini."
      ],
      "metadata": {
        "id": "btEkHeOb8hW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import openai\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"dataset.csv\")  # Replace with name of actual dataset\n",
        "\n",
        "# Group sentences by language\n",
        "language_data = defaultdict(list)\n",
        "language_data[\"Comanche\"] = df[\"Comanche\"].dropna().tolist()\n",
        "\n",
        "# Set few-shot and validation samples\n",
        "data = language_data[\"Comanche\"]\n",
        "few_shot_size = int(len(data) * 0.03)  # 3% for few-shot examples\n",
        "few_shot_samples = data[:few_shot_size]\n",
        "validation_samples = data[few_shot_size:]\n",
        "\n",
        "print(\"Few-shot samples:\", len(few_shot_samples))\n",
        "print(\"Validation samples:\", len(validation_samples))\n",
        "\n",
        "# OpenAI API key setup (replace with your actual API key)\n",
        "openai.api_key = \"******\"\n",
        "\n",
        "# Function to query GPT models\n",
        "def query_gpt(prompt, model):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a language identification expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {\"gpt-4o\": {}, \"gpt-4o-mini\": {}}\n",
        "\n",
        "x = len(few_shot_samples) + 1 # Iterate from 0 samples to number of few shot samples\n",
        "\n",
        "# Run tests for each model\n",
        "for model in results.keys():\n",
        "    print(f\"\\nRunning tests for model: {model}\")\n",
        "    for n in range(x):\n",
        "        examples = \"\\n\".join(\n",
        "            [f\"Example {i+1}: {sent} (Language: Comanche)\"\n",
        "             for i, sent in enumerate(few_shot_samples[:n])]\n",
        "        )\n",
        "        count_comanche = 0\n",
        "        for sentence in validation_samples:\n",
        "            prompt = f\"\"\"\n",
        "Here are examples of sentences and their languages:\n",
        "{examples}\n",
        "\n",
        "Now, what language is this sentence in?\n",
        "\n",
        "Sentence: {sentence}\n",
        "Reply with only the language itself.\n",
        "\"\"\"\n",
        "            predicted_lang = query_gpt(prompt, model=model)\n",
        "            if \"comanche\" in predicted_lang.lower():\n",
        "                count_comanche += 1\n",
        "        results[model][n] = count_comanche\n",
        "        print(f\"{model}, Few-shot examples: {n}, 'Comanche' predictions: {count_comanche}\")\n",
        "\n",
        "# Save results to CSV\n",
        "final_results = []\n",
        "for model, data in results.items():\n",
        "    for n, count in data.items():\n",
        "        final_results.append({\n",
        "            \"Model\": model,\n",
        "            \"Few-Shot Count\": n,\n",
        "            \"Comanche Predictions\": count\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(final_results)\n",
        "results_df.to_csv(\"comanche_comparison_results.csv\", index=False)\n",
        "print(\"Results saved to CSV\")"
      ],
      "metadata": {
        "id": "fo0WV_bYo9F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "x = list(range(0, len(few_shot_samples[\"Comanche\"]) + 1))\n",
        "\n",
        "plt.plot(x, [results[\"gpt-4o\"].get(n, 0) for n in x],\n",
        "         marker='o', linestyle='-', linewidth=2, label=\"GPT-4o\", color=\"#0000FE\")\n",
        "\n",
        "plt.plot(x, [results[\"gpt-4o-mini\"].get(n, 0) for n in x],\n",
        "         marker='o', linestyle='-', linewidth=2, label=\"GPT-4o-mini\", color=\"#C80000\")\n",
        "\n",
        "\n",
        "plt.xlabel('Number of Few-Shot Training Examples (n)', fontsize=12)\n",
        "plt.ylabel('Number of \\\"Comanche\\\" Predictions (%)', fontsize=10)\n",
        "plt.title('Effect of Few-Shot Examples on \\\"Comanche\\\" Predictions', fontsize=14)\n",
        "plt.xticks(x)\n",
        "plt.ylim(0, 105)\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.legend(title=\"OpenAI Model\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Om8yTGsULok9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
