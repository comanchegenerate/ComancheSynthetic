{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrgS36DufLuoCqC3dl1FlL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comanchegenerate/ComancheSynthetic/blob/main/language_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Original Zero Shot Tests"
      ],
      "metadata": {
        "id": "UsGP8GdOzVmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "7LZHcNj45YF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"dataset\") # Replace with actualt dataset name\n",
        "\n",
        "\n",
        "# Group sentences by language\n",
        "language_data = defaultdict(list)\n",
        "language_data[\"Comanche\"] = df[\"Comanche\"].dropna().tolist()\n",
        "\n",
        "print(language_data)"
      ],
      "metadata": {
        "id": "4CRpyXzK5apR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "zero_shot_samples = {lang: sentences[:len(language_data)] for lang, sentences in language_data.items()}\n",
        "\n",
        "print(zero_shot_samples)"
      ],
      "metadata": {
        "id": "pE5NCZ-j5f3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=\"***********\")  # Replace with your actual API key"
      ],
      "metadata": {
        "id": "IVT6Tfy75iP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # Use GPT-4o or your preferred model\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "tyskHE_85nGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-Shot Evaluation\n",
        "zero_shot_results = []\n",
        "for lang, test_sentences in zero_shot_samples.items():\n",
        "    for sentence in test_sentences:\n",
        "        prompt = f\"You are a linguistics expert who knows every single language that exists in this world. What language is this sentence in?\\n\\nSentence: {sentence}. Reply with only the language itself and nothing else.\"\n",
        "        predicted_lang = query_gpt(prompt)\n",
        "        zero_shot_results.append([lang, sentence, predicted_lang])"
      ],
      "metadata": {
        "id": "KpzVchnL5oK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and save\n",
        "zero_shot_df = pd.DataFrame(zero_shot_results, columns=[\"True Language\", \"Sentence\", \"Predicted Language\"])\n",
        "\n",
        "# Save outputs\n",
        "zero_shot_df.to_csv(\"comanche_id_zero_shot.csv\", index=False)\n",
        "\n",
        "print(\"Experiment complete! Results saved.\")"
      ],
      "metadata": {
        "id": "AasiLEE35vID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few-Shot Testing with Comanche and English"
      ],
      "metadata": {
        "id": "HUsGBX5RNpUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import openai\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"dataset\")  # Replace with actual dataset name\n",
        "\n",
        "# Group sentences by language\n",
        "language_data = defaultdict(list)\n",
        "language_data[\"Comanche\"] = df[\"Comanche\"].dropna().tolist()\n",
        "language_data[\"English\"] = df[\"English\"].dropna().tolist()\n",
        "\n",
        "# Organize and shuffle the data\n",
        "comanche_data = language_data[\"Comanche\"]\n",
        "eng_data = language_data[\"English\"]\n",
        "\n",
        "random.shuffle(comanche_data)\n",
        "random.shuffle(eng_data)\n",
        "\n",
        "# Set few-shot and validation samples\n",
        "few_shot_size = 5\n",
        "\n",
        "# Designate few-shot samples and validation set for Comanche and English from shuffled list\n",
        "comanche_few_shot_samples = comanche_data[:few_shot_size]\n",
        "comanche_validation_samples = comanche_data[few_shot_size:105]\n",
        "\n",
        "eng_few_shot_samples = eng_data[:few_shot_size]\n",
        "eng_validation_samples = eng_data[few_shot_size:105]\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=\"********\")  # Replace with your actual API key\n",
        "\n",
        "# Function to query GPT models\n",
        "def query_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Initialize results dictionary\n",
        "model_name = \"gpt-4o\"\n",
        "results = {\n",
        "    model_name: {\n",
        "        \"Comanche\": defaultdict(int),\n",
        "        \"English\": defaultdict(int)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Iterate over number of few-shot examples\n",
        "for n in range(few_shot_size + 1):  # 0 to 5\n",
        "\n",
        "    # Prepare few-shot examples\n",
        "    comanche_examples = \"\\n\".join(\n",
        "        [f\"Sentence: {sent}\\nLanguage: Comanche\" for sent in comanche_few_shot_samples[:n]]\n",
        "    )\n",
        "    eng_examples = \"\\n\".join(\n",
        "        [f\"Sentence: {sent}\\nLanguage: English\" for sent in eng_few_shot_samples[:n]]\n",
        "    )\n",
        "    few_shot_prompt = \"\\n\".join([comanche_examples, eng_examples]).strip()\n",
        "\n",
        "    # Evaluate Comanche validation sentences\n",
        "    correct_comanche = 0\n",
        "    for sent in comanche_validation_samples:\n",
        "        prompt = f\"\"\"\n",
        "{few_shot_prompt}\n",
        "\n",
        "Sentence: {sent}\n",
        "What language is this sentence in? Reply with only the language name.\n",
        "\"\"\"\n",
        "        predicted_lang = query_gpt(prompt).lower().strip()\n",
        "        if predicted_lang == \"comanche\":\n",
        "            correct_comanche += 1\n",
        "    results[model_name][\"Comanche\"][n] = correct_comanche\n",
        "\n",
        "    # Evaluate English validation sentences\n",
        "    correct_english = 0\n",
        "    for sent in eng_validation_samples:\n",
        "        prompt = f\"\"\"\n",
        "{few_shot_prompt}\n",
        "\n",
        "Sentence: {sent}\n",
        "What language is this sentence in? Reply with only the language name.\n",
        "\"\"\"\n",
        "        predicted_lang = query_gpt(prompt).lower().strip()\n",
        "        if predicted_lang == \"english\":\n",
        "            correct_english += 1\n",
        "    results[model_name][\"English\"][n] = correct_english\n",
        "\n",
        "    print(f\"n={n}: Comanche Correct={correct_comanche}, English Correct={correct_english}\")\n",
        "\n",
        "# Convert results to DataFrame and save\n",
        "results_list = []\n",
        "for n in range(few_shot_size + 1):\n",
        "    results_list.append({\n",
        "        \"Few-Shot Count\": n,\n",
        "        \"Comanche Correct\": results[model_name][\"Comanche\"][n],\n",
        "        \"English Correct\": results[model_name][\"English\"][n]\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results_list)\n",
        "results_df.to_csv(\"comanche_classification_results.csv\", index=False)\n",
        "print(\"Results saved to CSV.\")"
      ],
      "metadata": {
        "id": "pX9Fh9_sy8cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load results\n",
        "results_df = pd.read_csv(\"resulting_csv\")\n",
        "\n",
        "# Set up plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot data with markers\n",
        "plt.plot(results_df['Few-Shot Count'],\n",
        "         results_df['Comanche Correct'],\n",
        "         color='#0000FE',\n",
        "         marker='o',\n",
        "         markersize=8,\n",
        "         markeredgecolor='w',\n",
        "         linewidth=2.5,\n",
        "         label='Comanche')\n",
        "\n",
        "plt.plot(results_df['Few-Shot Count'],\n",
        "         results_df['English Correct'],\n",
        "         color='#C80000',\n",
        "         marker='s',\n",
        "         markersize=8,\n",
        "         markeredgecolor='w',\n",
        "         linewidth=2.5,\n",
        "         label='English')\n",
        "\n",
        "# Configure axes\n",
        "plt.title('Effect of Few-Shot Examples on Comanche vs English Predictions', fontsize=14)\n",
        "plt.xlabel('Number of Few-Shot Examples', fontsize=12)\n",
        "plt.ylabel('Correct Predictions', fontsize=12)\n",
        "plt.xticks(results_df['Few-Shot Count'])\n",
        "plt.ylim(0, 105)\n",
        "plt.xlim(-0.1, 5.1)\n",
        "\n",
        "# Add light grid\n",
        "plt.grid(True,\n",
        "        linestyle='--',\n",
        "        linewidth=0.7,\n",
        "        alpha=0.4)\n",
        "\n",
        "# Add legend\n",
        "plt.legend(loc='lower right', frameon=True)\n",
        "\n",
        "# Save and show\n",
        "plt.tight_layout()\n",
        "plt.savefig('clean_marker_plot.png', dpi=300, transparent=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ruYO09lYGxQ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}